threshold <- 0.5
test <- test %>% mutate(prediction = case_when(predicted.probability < threshold ~ F,
predicted.probability > threshold ~ T))
#confusion matrix
table(test$prediction, test$found.weapon) #an idea of how well the classifer is doing (predictions on left), the
#real one - on top(actually)
rm(list=ls())
install.packages("tabulizer")
library(tabulizer)
library(tabulizer)
library(rJava)
rm(list=ls())
library(tidyverse)
getwd()
library(tidyverse)
condoms <- read.csv("/Users/madisonvolpe/Documents/Projects/CondomDistribution/Condoms.csv")
names(condoms)
View(condoms)
sapply(condoms, is.na)
sum(sapply(condoms,is.na))
apply(condoms,2,is.na)
cumsum(apply(condoms,2,is.na))
colSums(apply(condoms,2,is.na))
names(colSums(apply(condoms,2,is.na)))
colSums(apply(condoms,2,is.na))==319
names(colSums(apply(condoms,2,is.na))==319)
## drop columns with all na values
colSums(apply(condoms,2,is.na))==nrow(condoms)
## drop columns with all na values
drop<-colSums(apply(condoms,2,is.na))==nrow(condoms)
names(drop[drop==TRUE])
condoms[,-drop]
ncol(condoms[,-drop])
drop<-colSums(apply(condoms,2,is.na))==nrow(condoms)
drop<-names(drop[drop==TRUE])
ncol(condoms[,-drop])
ncol(condoms[,-c(drop)])
condoms[!ames(condoms)  %in% drop]
condoms[!names(condoms)  %in% drop]
ncol(condoms[!names(condoms)  %in% drop])
condoms_c <- condoms[!names(condoms)  %in% drop]
View(condoms_c)
condoms_c[-9:17]
condoms_c[-c(9:17)]
## drop extraneous variables
condoms_c <- condoms_c[-c(9:17)]
View(condoms_c)
View(condoms)
library(tidyverse)
condoms <- read.csv("/Users/madisonvolpe/Documents/Projects/CondomDistribution/Condoms.csv")
### data cleaning ###
## drop columns with all na values
drop<-colSums(apply(condoms,2,is.na))==nrow(condoms)
drop<-names(drop[drop==TRUE])
condoms_c <- condoms[!names(condoms)  %in% drop]
View(condoms_c)
## drop extraneous variables
condoms_c <- condoms_c[,-c(9:17,21)]
View(condoms_c)
## check the data type for each column
sapply(condoms_c,str)
condoms_c %>%
group_by(Borough) %>%
summarise(CondomSites = n())
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.==T & FC2..Female.Insertive.Condoms.== T & Lubricant== T) %>%
n()
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.==T & FC2..Female.Insertive.Condoms.== T & Lubricant== T) %>%
count(FacilityName)
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.==T & FC2..Female.Insertive.Condoms.== T & Lubricant== T) %>%
summarise(n=n())
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.==T & FC2..Female.Insertive.Condoms.== T & Lubricant== T)
sapply(condoms_c$Condoms..Male.)
sapply(condoms_c$Condoms..Male.,str)
str(condoms_c$Condoms..Male.)
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.=="true" & FC2..Female.Insertive.Condoms.== "true" & Lubricant== "true")
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.=="true" & FC2..Female.Insertive.Condoms.== "true" & Lubricant== "true") %>%
count(FacilityName)
## number of sites that offer male condoms, female condoms, and lubricant
condoms_c %>%
filter(Condoms..Male.=="true" & FC2..Female.Insertive.Condoms.== "true" & Lubricant== "true") %>%
summarise(n=n())
## number of sites that offer male condoms, female condoms, and lubricant by borough
condoms_c %>%
filter(Condoms..Male.=="true" & FC2..Female.Insertive.Condoms.== "true" & Lubricant== "true") %>%
group_by(Borough)%>%
summarise(n=n())
unique(condoms_c$NTA)
rm(list=ls())
getwd()
ePrefs <- makeFirefoxProfile(
list(
browser.download.dir = "/home/seluser/Downloads",
"browser.download.folderList" = 2L,
"browser.download.manager.showWhenStarting" = FALSE,
"browser.helperApps.neverAsk.saveToDisk" = "multipart/x-zip,application/zip,application/x-zip-compressed,application/x-compressed,application/msword,application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,  application/excel, application/vnd.ms-excel, application/x-excel, application/x-msexcel, application/octet-stream"))
library(tidyverse)
library(rvest)
library(XML)
library(RSelenium)
ePrefs <- makeFirefoxProfile(
list(
browser.download.dir = "/home/seluser/Downloads",
"browser.download.folderList" = 2L,
"browser.download.manager.showWhenStarting" = FALSE,
"browser.helperApps.neverAsk.saveToDisk" = "multipart/x-zip,application/zip,application/x-zip-compressed,application/x-compressed,application/msword,application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,  application/excel, application/vnd.ms-excel, application/x-excel, application/x-msexcel, application/octet-stream"))
remDR <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
, extraCapabilities = prefs)
remDR <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
, extraCapabilities = ePrefs)
remDR$open()
remDR$setImplicitWaitTimeout(3000)
#create urls
urls <- paste("http://tidc.tamu.edu/Public.Net/Reports/DataSheet.aspx?cid=",1:254,sep="")
#navigate
remDR$navigate(urls[1])
remDR$screenshot(display = T)
#find elements
DropDown <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_cbxExportOptions_B-1"]')
SubmitButton <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_btnViewReport_CD"]')
#click elements
DropDown$clickElement()
remDR$screenshot(display = T)
DropDown$sendKeysToActiveElement(list(key="down_arrow"))
remDR$screenshot(display = T)
SubmitButton$clickElement()
DropDown$sendKeysToActiveElement(list(key = "enter"))
SubmitButton$clickElement()
list.files("/Users/madisonvolpe/Test/")
rm(list=ls())
library(tidyverse)
library(rvest)
library(XML)
library(RSelenium)
### initiate driver ###
ePrefs <- makeFirefoxProfile(
list(
browser.download.dir = "/home/seluser/Downloads",
"browser.download.folderList" = 2L,
"browser.download.manager.showWhenStarting" = FALSE,
"browser.helperApps.neverAsk.saveToDisk" = "multipart/x-zip,application/zip,application/x-zip-compressed,application/x-compressed,application/msword,application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,  application/excel, application/vnd.ms-excel, application/x-excel, application/x-msexcel, application/octet-stream"))
# open docker
# to initate server, run:
# docker run hello-world
# docker run -d -p 4445:4444 selenium/standalone-firefox:2.53.1
remDR <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
, extraCapabilities = ePrefs)
remDR$open()
remDR$setImplicitWaitTimeout(3000)
#create urls
urls <- paste("http://tidc.tamu.edu/Public.Net/Reports/DataSheet.aspx?cid=",1:254,sep="")
### For Loop to Download data ###
for(i in 1:length(urls)){
remDR$navigate(urls[i])
#find elements
DropDown <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_cbxExportOptions_B-1"]')
SubmitButton <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_btnViewReport_CD"]')
#click drop down and navigate to xls
DropDown$clickElement()
DropDown$sendKeysToActiveElement(list(key="down_arrow"))
DropDown$sendKeysToActiveElement(list(key = "enter"))
#select submit button to automatically download data
SubmitButton$clickElement()
}
remDR$screenshot(display=TRUE)
library(tidyverse)
library(rvest)
library(XML)
library(RSelenium)
### initiate driver ###
ePrefs <- makeFirefoxProfile(
list(
browser.download.dir = "/home/seluser/Downloads",
"browser.download.folderList" = 2L,
"browser.download.manager.showWhenStarting" = FALSE,
"browser.helperApps.neverAsk.saveToDisk" = "multipart/x-zip,application/zip,application/x-zip-compressed,application/x-compressed,application/msword,application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,  application/excel, application/vnd.ms-excel, application/x-excel, application/x-msexcel, application/octet-stream"))
# open docker
# to initate server, run:
# docker run hello-world
# docker run -d -p 4445:4444 selenium/standalone-firefox:2.53.1
remDR <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
, extraCapabilities = ePrefs)
remDR$open()
remDR$setImplicitWaitTimeout(3000)
#create urls
urls <- paste("http://tidc.tamu.edu/Public.Net/Reports/DataSheet.aspx?cid=",1:254,sep="")
### For Loop to Download data ###
for(i in 1:5){
remDR$navigate(urls[i])
#find elements
DropDown <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_cbxExportOptions_B-1"]')
SubmitButton <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_btnViewReport_CD"]')
#click drop down and navigate to xls
DropDown$clickElement()
DropDown$sendKeysToActiveElement(list(key="down_arrow"))
DropDown$sendKeysToActiveElement(list(key = "enter"))
#select submit button to automatically download data
SubmitButton$clickElement()
}
remDR$screenshot(display = T)
library(tidyverse)
library(rvest)
library(XML)
library(RSelenium)
### initiate driver ###
ePrefs <- makeFirefoxProfile(
list(
browser.download.dir = "/home/seluser/Downloads",
"browser.download.folderList" = 2L,
"browser.download.manager.showWhenStarting" = FALSE,
"browser.helperApps.neverAsk.saveToDisk" = "multipart/x-zip,application/zip,application/x-zip-compressed,application/x-compressed,application/msword,application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,  application/excel, application/vnd.ms-excel, application/x-excel, application/x-msexcel, application/octet-stream"))
# open docker
# to initate server, run:
# docker run hello-world
# docker run -d -p 4445:4444 selenium/standalone-firefox:2.53.1
remDR <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
, extraCapabilities = ePrefs)
remDR$open()
remDR$setImplicitWaitTimeout(3000)
#create urls
urls <- paste("http://tidc.tamu.edu/Public.Net/Reports/DataSheet.aspx?cid=",1:254,sep="")
### For Loop to Download data ###
for(i in 1:5){
remDR$navigate(urls[i])
#find elements
DropDown <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_cbxExportOptions_B-1"]')
SubmitButton <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_btnViewReport_CD"]')
#click drop down and navigate to xls
DropDown$clickElement()
DropDown$sendKeysToActiveElement(list(key="down_arrow"))
DropDown$clickElement
#select submit button to automatically download data
SubmitButton$clickElement()
}
for(i in 1:5){
remDR$navigate(urls[i])
#find elements
DropDown <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_cbxExportOptions_B-1"]')
SubmitButton <- remDR$findElement(using = 'xpath',
value = '//*[@id="ctl00_MainContent_ASPxRoundPanel1_btnViewReport_CD"]')
#click drop down and navigate to xls
DropDown$clickElement()
DropDown$sendKeysToActiveElement(list(key="down_arrow"))
DropDown$clickElement()
#select submit button to automatically download data
SubmitButton$clickElement()
}
?download.file
download.file("http://media.graytvinc.com/documents/Booking+Report+1-1-19.pdf")
rm(list=ls())
## Download from
rep(1:12, c(1,2))
## Download from
rep(1:12, c(1:12))
seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day")
?as.date
?as.Date
seq(as.Date("1-1-2018", fomat = "%m-%d-%Y"), as.Date("1-1-2019", "%m-%d-%Y"), "day")
seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day")
dates <- seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day")
dates <- data.frame(seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
View(dates)
dates$weekday <- weekdays(dates$dates.seq)
View(dates)
View(dates)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), "%Y/%m/%d")
View(dates)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y/%m/%d")
dates$new
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y/%m/%d")
View(dates)
str(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(dates$newdate, "%m-%d-%y")
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
## remove preceding 0s
gsub("^0","",dates$new)
## remove preceding 0s
dates$new <- gsub("^0","",dates$new)
grepl("//d+", dates$new)
grepl("\\d+", dates$new)
grepl("\\d+//\", dates$new)
grepl("\\d+\", dates$new)
grepl("\\d+", dates$new)
grepl("\\d+\", dates$new)
grepl("\\d+\0", dates$new)
grepl("0\\d", dates$new)
dates$new <- gsub("0\\d", "",dates$new)
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
dates$new <- gsub("^0","",dates$new)
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new)=TRUE){
dates$new <- gsub("0", "",dates$new)
}
}
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new)==TRUE){
dates$new <- gsub("0", "",dates$new)
}
}
dates$new[9]
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
## remove preceding 0s
dates$new <- gsub("^0","",dates$new)
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new[i])==TRUE){
dates$new[i] <- gsub("0", "",dates$new[i])
}
}
View(dates)
#create URLS
baseURL<- "http://media.graytvinc.com/documents/Booking+Report+"
dates$new
URLs <- paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf")
URLs[1]
URLs <- paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep="")
URLs[1]
download.folder = '~/Desktop/LeonCountyBookings/'
getwd()
setwd("/Users/madisonvolpe/Desktop")
download.file(URLs[1],"test1.pdf", method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
getwd()
setwd("/Users/madisonvolpe/Desktop/LeonCountyBookings")
URLs <- data.frame(paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep=""))
URLs$ID <- dates$new
names(URLs)
baseURL<- "http://media.graytvinc.com/documents/Booking+Report+"
URLs <- data.frame(URL = paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep=""))
URLs$ID <- dates$new
View(URLs)
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
download.file(URLs$URL[i], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
}
names(URLs)
download.file(URLs$URL[1], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
View(URLs)
str(URLs)
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
## remove preceding 0s
dates$new <- gsub("^0","",dates$new)
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new[i])==TRUE){
dates$new[i] <- gsub("0", "",dates$new[i])
}
}
#create URLS
baseURL<- "http://media.graytvinc.com/documents/Booking+Report+"
URLs <- data.frame(URL = as.character(paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep="")))
URLs$ID <- dates$new
str(URLs)
URLs$URL <- as.character(URLs$URL)
names(URLs)
str(URLs)
#download folder
download.folder = '~/Desktop/LeonCountyBookings/'
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
download.file(URLs$URL[i], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
}
library(purrr)
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
possibly(download.file(URLs$URL[i], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"), otherwise = NA))
}
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
possibly(download.file(URLs$URL[i], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra")), otherwise = NA))
}
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
possibly(download.file(URLs$URL[i], pdf.name, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra")), otherwise = NA)
}
get_data <- function(x, y){
download.file(x, y, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra")), otherwise = NA))
}
download.file(x, y, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
get_data <- function(x, y){
download.file(x, y, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
}
get_data(URLs$URL[1], "test1.pdf")
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
library(purrr)
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
## Remove preceding 0s
dates$new <- gsub("^0","",dates$new)
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new[i])==TRUE){
dates$new[i] <- gsub("0", "",dates$new[i])
}
}
# Create URLS
baseURL<- "http://media.graytvinc.com/documents/Booking+Report+"
URLs <- data.frame(URL = paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep=""))
URLs$ID <- dates$new
URLs$URL <- as.character(URLs$URL)
# Download folder
download.folder = '~/Desktop/LeonCountyBookings/'
rm(list=ls())
##### LEON COUNTY SHERIFF'S OFFICE: DAILY BOOKING REPORT #####
library(purrr)
## Download from
dates <- data.frame(dates.seq = seq(as.Date("2018/1/1"), as.Date("2019/1/1"), "day"))
dates$weekday <- weekdays(dates$dates.seq)
## Reformat dates to match pdf
dates$new <- strptime(as.character(dates$dates.seq), format = "%Y-%m-%d")
dates$new <- format(as.Date(dates$new, format = "%Y-%m-%d"), "%m-%d-%y")
## Remove preceding 0s
dates$new <- gsub("^0","",dates$new)
for(i in 1:nrow(dates)){
if(grepl("0\\d", dates$new[i])==TRUE){
dates$new[i] <- gsub("0", "",dates$new[i])
}
}
# Create URLS
baseURL<- "http://media.graytvinc.com/documents/Booking+Report+"
URLs <- data.frame(URL = paste("http://media.graytvinc.com/documents/Booking+Report+",dates$new, ".pdf",sep=""))
URLs$ID <- dates$new
URLs$URL <- as.character(URLs$URL)
# Download folder
download.folder = '~/Desktop/LeonCountyBookings/'
get_data <- function(x, y){
download.file(x, y, method = 'auto', quiet = FALSE, mode = "w",
cacheOK = TRUE, extra = getOption("download.file.extra"))
}
get_data2 <- possibly(get_data, otherwise = NA)
names(URLs)
for(i in 1:nrow(URLs)){
pdf.name <- paste(download.folder, URLs$ID[i], '.pdf', sep = "")
get_data2(URLs$URL[i], pdf.name)
}
URLs$URL[1]
get_data2(paste("http://media.graytvinc.com/documents/Booking+Report+","1-2-19",".pdf",sep=""),
paste(download.folder,'1-2-19', '.pdf', sep = ""))
getwd()
get_data2(paste("http://media.graytvinc.com/documents/Booking+Report+","1-2-19",".pdf",sep=""),
paste(download.folder,'1-2-19','.pdf', sep = ""))
